---
http_interactions:
- request:
    method: get
    uri: https://api.notion.com/v1/pages/838177043c474405bcbc09826a13153b
    body:
      encoding: US-ASCII
      string: ''
    headers:
      Accept:
      - application/json; charset=utf-8
      User-Agent:
      - Notion Ruby Client/1.2.2
      Authorization:
      - Bearer <NOTION_TOKEN>
      Notion-Version:
      - '2022-02-22'
  response:
    status:
      code: 200
      message: OK
    headers:
      date:
      - Thu, 25 Jan 2024 05:16:49 GMT
      content-type:
      - application/json; charset=utf-8
      transfer-encoding:
      - chunked
      connection:
      - keep-alive
      x-powered-by:
      - Express
      x-notion-request-id:
      - 92fc6fc2-bd35-418d-a97e-77d6f3082b00
      etag:
      - W/"5ff-azuRpjUjYA3YjmnMDZ4sfB4BycI"
      vary:
      - Accept-Encoding
      content-encoding:
      - gzip
      cf-cache-status:
      - DYNAMIC
      set-cookie:
      - __cf_bm=PsikfTirm8sGboYiUUuMN7AsBIbda_CZedNPNLGcXqI-1706159809-1-AWyKsncOIs0kv0fVP1YA5SLOH1VeFl5GvzZOP73JytGL9F4QVv7NSjqkhO9Cpngi7Ko9OcUIrkLKZQyiObeNvy0=;
        path=/; expires=Thu, 25-Jan-24 05:46:49 GMT; domain=.notion.com; HttpOnly;
        Secure; SameSite=None
      server:
      - cloudflare
      cf-ray:
      - 84ae0bdb2f8330b6-ICN
    body:
      encoding: UTF-8
      string: '{"object":"page","id":"83817704-3c47-4405-bcbc-09826a13153b","created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"cover":null,"icon":{"type":"file","file":{"url":"https://prod-files-secure.s3.us-west-2.amazonaws.com/5758ba68-cfd2-4a36-b622-fe9551804f02/1d07fa7e-bc25-445b-8981-85b6fd1baa2e/%E1%84%8E%E1%85%B1%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%28%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45HZZMZUHI%2F20240125%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20240125T051649Z&X-Amz-Expires=3600&X-Amz-Signature=7907508feb556ec3b50448a42ba69a7165f78472cb1609b0f197e96e768528c3&X-Amz-SignedHeaders=host&x-id=GetObject","expiry_time":"2024-01-25T06:16:49.897Z"}},"parent":{"type":"workspace","workspace":true},"archived":false,"properties":{"title":{"id":"title","type":"title","title":[{"type":"text","text":{"content":"CV","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"CV","href":null}]}},"url":"https://www.notion.so/CV-838177043c474405bcbc09826a13153b","public_url":"https://organized-manchego-5df.notion.site/CV-838177043c474405bcbc09826a13153b","request_id":"92fc6fc2-bd35-418d-a97e-77d6f3082b00"}'
  recorded_at: Thu, 25 Jan 2024 05:16:49 GMT
- request:
    method: get
    uri: https://api.notion.com/v1/blocks/838177043c474405bcbc09826a13153b/children
    body:
      encoding: US-ASCII
      string: ''
    headers:
      Accept:
      - application/json; charset=utf-8
      User-Agent:
      - Notion Ruby Client/1.2.2
      Authorization:
      - Bearer <NOTION_TOKEN>
      Notion-Version:
      - '2022-02-22'
  response:
    status:
      code: 200
      message: OK
    headers:
      date:
      - Thu, 25 Jan 2024 05:16:50 GMT
      content-type:
      - application/json; charset=utf-8
      transfer-encoding:
      - chunked
      connection:
      - keep-alive
      x-powered-by:
      - Express
      x-notion-request-id:
      - 55953994-83c4-4a48-9dd8-bba0a4ee7c06
      etag:
      - W/"1d348-qVbydgrvcBbxe9/TFjXZK4J1gc8"
      vary:
      - Accept-Encoding
      content-encoding:
      - gzip
      cf-cache-status:
      - DYNAMIC
      set-cookie:
      - __cf_bm=nFSHtnPa42b4aCXtQnI_c6tUhwYMbY69TZIf7C7sBjo-1706159810-1-AVgdVblBx8szHyjhT4pzy2VMABHEAiglmUe8IoRIYUZ320MrVERwnwZ/wbHmxu9OrBbnHgxvklFmK1c2v+mxMGk=;
        path=/; expires=Thu, 25-Jan-24 05:46:50 GMT; domain=.notion.com; HttpOnly;
        Secure; SameSite=None
      server:
      - cloudflare
      cf-ray:
      - 84ae0bdc7d9f3279-ICN
    body:
      encoding: UTF-8
      string: '{"object":"list","results":[{"object":"block","id":"2750c0c7-0478-4f5f-8b45-28524c14b363","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T16:34:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[],"color":"gray"}},{"object":"block","id":"603e3160-8dc0-4f49-911a-352d804f0beb","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T06:57:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"37b57799-74c7-437f-bd5b-15dce854a8ef","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T10:16:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Biography","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Biography","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"8ce6a98a-50ad-4a10-8e60-86dd9cb0bdd2","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T07:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":"I
        work on overcoming instability and noisy data of Affective computing in the
        wild setting. Throughout my research, I have studied various kinds of topics
        to help AI deal with real-world problems in emotion recognition. Specifically,
        I am interested in advancing AI to better inference facial expression recognition
        and physiological signal sensing, such as in remote photoplethysmography and
        breathing rate.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"I
        work on overcoming instability and noisy data of Affective computing in the
        wild setting. Throughout my research, I have studied various kinds of topics
        to help AI deal with real-world problems in emotion recognition. Specifically,
        I am interested in advancing AI to better inference facial expression recognition
        and physiological signal sensing, such as in remote photoplethysmography and
        breathing rate.","href":null}],"color":"gray"}},{"object":"block","id":"fc71547c-5266-4539-b627-60924852026c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:06:00.000Z","last_edited_time":"2024-01-22T08:07:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":true,"archived":false,"type":"column_list","column_list":{}},{"object":"block","id":"cb3f9816-a972-4e00-9ad1-7ef0c5fa9359","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T16:34:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"a65d9784-a50b-4f27-b7aa-38c735c538c3","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T16:34:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Publications
        [","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Publications
        [","href":null},{"type":"text","text":{"content":"Google Scholar Profile","link":{"url":"https://scholar.google.co.kr/citations?user=lU9NpJUAAAAJ&hl=en"}},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Google
        Scholar Profile","href":"https://scholar.google.co.kr/citations?user=lU9NpJUAAAAJ&hl=en"},{"type":"text","text":{"content":"]","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"0f8e0098-ce7a-46f8-9667-caea1a3c4301","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:26:00.000Z","last_edited_time":"2024-01-22T09:56:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":"[C#]:
        Conference, [J#]: Journal, [W#]: workshops (#: Count)","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C#]:
        Conference, [J#]: Journal, [W#]: workshops (#: Count)","href":null}],"color":"default"}},{"object":"block","id":"e0296776-1f89-45c3-b917-7f05ca8e29f7","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T08:44:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2023","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2023","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"20efdfe3-0877-4dbf-a50b-80c0bbe8d9e6","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:47:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J11]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J11]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Jaemu Oh, Hojoon You,
        and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Jaemu Oh, Hojoon You, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Improving
        Remote Photoplethysmography Performance through Deep-Learning-Based Real-Time
        Skin Segmentation Network.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Improving
        Remote Photoplethysmography Performance through Deep-Learning-Based Real-Time
        Skin Segmentation Network.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Electronics","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Electronics","href":null},{"type":"text","text":{"content":" 12,
        no. 17 (2023): 3729.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 12,
        no. 17 (2023): 3729.","href":null}],"color":"default"}},{"object":"block","id":"6dc864c9-bfcc-4921-a9d0-5747d2839d52","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:57:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J10]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J10]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Seunghyun Kim, Byeongseon
        An, Hyunsoo Seo, Shinwi Park, and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Seunghyun Kim, Byeongseon An, Hyunsoo Seo, Shinwi Park, and Eui Chul Lee.
        ","href":null},{"type":"text","text":{"content":"Noise-Assessment-Based Screening
        Method for Remote Photoplethysmography Estimation.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Noise-Assessment-Based
        Screening Method for Remote Photoplethysmography Estimation.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Applied
        Sciences","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Applied
        Sciences","href":null},{"type":"text","text":{"content":" 13, no. 17 (2023):
        9818.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 13,
        no. 17 (2023): 9818.","href":null}],"color":"default"}},{"object":"block","id":"e0354384-3f62-4bcb-95b1-3e16c21fe867","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:57:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J9]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J9]","href":null},{"type":"text","text":{"content":"
        Jin, Eunju, Hyunju Kang, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Jin, Eunju, Hyunju Kang, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Seung Gun Lee, and Eui
        Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Seung Gun Lee, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Analysis
        of Nursing Students’ Nonverbal Communication Patterns during Simulation Practice:
        A Pilot Study.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Analysis
        of Nursing Students’ Nonverbal Communication Patterns during Simulation Practice:
        A Pilot Study.","href":null},{"type":"text","text":{"content":" In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Healthcare","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Healthcare","href":null},{"type":"text","text":{"content":",
        vol. 11, no. 16, p. 2335. MDPI, 2023.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        vol. 11, no. 16, p. 2335. MDPI, 2023.","href":null}],"color":"default"}},{"object":"block","id":"8edbf65d-e1fb-4a5e-9711-beaeeb34453a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:59:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J8]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J8]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Seunghyun Kim, and Eui
        Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Seunghyun Kim, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Fast
        and Accurate Facial Expression Image Classification and Regression Method
        Based on Knowledge Distillation.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Fast
        and Accurate Facial Expression Image Classification and Regression Method
        Based on Knowledge Distillation.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Applied
        Sciences","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Applied
        Sciences","href":null},{"type":"text","text":{"content":" 13, no. 11 (2023):
        6409.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 13,
        no. 11 (2023): 6409.","href":null}],"color":"default"}},{"object":"block","id":"c7e54347-e379-4ef5-af9d-352ace4dcc90","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J7]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J7]","href":null},{"type":"text","text":{"content":"
        You, Hojoon, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        You, Hojoon, ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Jaemu Oh, and Eui Chul
        Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Jaemu Oh, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Efficient
        and Low Color Information Dependency Skin Segmentation Model.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Efficient
        and Low Color Information Dependency Skin Segmentation Model.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Mathematics","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mathematics","href":null},{"type":"text","text":{"content":" 11,
        no. 9 (2023): 2057.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 11,
        no. 9 (2023): 2057.","href":null}],"color":"default"}},{"object":"block","id":"315dcba4-0eb8-4294-b3ff-9840315cf22c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[W1]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[W1]","href":null},{"type":"text","text":{"content":"
        Kim, Seunghyun, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Kim, Seunghyun, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Multi-View
        Body Image-Based Prediction of Body Mass Index and Various Body Part Sizes.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Multi-View
        Body Image-Based Prediction of Body Mass Index and Various Body Part Sizes.","href":null},{"type":"text","text":{"content":"
        In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Proceedings of the IEEE/CVF
        Conference on Computer Vision and Pattern Recognition","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Proceedings
        of the IEEE/CVF Conference on Computer Vision and Pattern Recognition","href":null},{"type":"text","text":{"content":",
        pp. 6033-6040. 2023.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 6033-6040. 2023.","href":null}],"color":"default"}},{"object":"block","id":"e14de6ab-ccdb-47e2-b798-33052a72a411","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:06:00.000Z","last_edited_time":"2024-01-22T09:06:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2022","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2022","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"759382ef-a770-48d7-9040-917c78415e80","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J6]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J6]","href":null},{"type":"text","text":{"content":"
        Hwang, Hyeonsang, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Hwang, Hyeonsang, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"A real-time
        remote respiration measurement method with improved robustness based on a
        CNN model.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"A
        real-time remote respiration measurement method with improved robustness based
        on a CNN model.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Applied
        Sciences","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Applied
        Sciences","href":null},{"type":"text","text":{"content":" 12, no. 22 (2022):
        11603.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 12,
        no. 22 (2022): 11603.","href":null}],"color":"default"}},{"object":"block","id":"46170dbf-5306-47dd-be6a-25bb36296b4c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:06:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J5]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J5]","href":null},{"type":"text","text":{"content":"
        Jang, Woohyuk, Chaewon Lee, Dae Sik Jeong, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Jang, Woohyuk, Chaewon Lee, Dae Sik Jeong, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Multi-Currency
        Integrated Serial Number Recognition Model of Images Acquired by Banknote
        Counters.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Multi-Currency
        Integrated Serial Number Recognition Model of Images Acquired by Banknote
        Counters.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 22,
        no. 22 (2022): 8612.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 22,
        no. 22 (2022): 8612.","href":null}],"color":"default"}},{"object":"block","id":"d2a9abd2-5e89-4cce-8181-8fa2e22360ac","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[C3]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C3]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Hojoon You, Jaemu Oh,
        and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Hojoon You, Jaemu Oh, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Extremely
        Lightweight Skin Segmentation Networks to Improve Remote Photoplethysmography
        Measurement.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Extremely
        Lightweight Skin Segmentation Networks to Improve Remote Photoplethysmography
        Measurement.","href":null},{"type":"text","text":{"content":" In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"International Conference
        on Intelligent Human Computer Interaction","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"International
        Conference on Intelligent Human Computer Interaction","href":null},{"type":"text","text":{"content":",
        pp. 454-459. Cham: Springer Nature Switzerland, 2022.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 454-459. Cham: Springer Nature Switzerland, 2022.","href":null}],"color":"default"}},{"object":"block","id":"a75770e6-fa9b-40e2-b4b1-260c7221b092","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:53:00.000Z","last_edited_time":"2024-01-22T09:53:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2021","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2021","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"0bdf295e-9cb0-4dc0-b7e4-81f10764eded","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[C2]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C2]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Kyungwon Jin, Youngwon
        Kim, Jee Hang Lee, and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Kyungwon Jin, Youngwon Kim, Jee Hang Lee, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"A
        comparative analysis on the impact of face tracker and skin segmentation onto
        improving the performance of real-time remote photoplethysmography.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"A
        comparative analysis on the impact of face tracker and skin segmentation onto
        improving the performance of real-time remote photoplethysmography.","href":null},{"type":"text","text":{"content":"
        In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Intelligent Human Computer
        Interaction: 12th International Conference, IHCI 2020, Daegu, South Korea,
        November 24–26, 2020, Proceedings, Part II 12","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Intelligent
        Human Computer Interaction: 12th International Conference, IHCI 2020, Daegu,
        South Korea, November 24–26, 2020, Proceedings, Part II 12","href":null},{"type":"text","text":{"content":",
        pp. 27-37. Springer International Publishing, 2021.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 27-37. Springer International Publishing, 2021.","href":null}],"color":"default"}},{"object":"block","id":"66557549-d03e-4ced-9f37-7c7bf54cdb78","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:53:00.000Z","last_edited_time":"2024-01-22T09:53:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2020","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2020","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"8f3bafe7-dff4-4074-af3d-5e330921434f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J4]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J4]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Siamese
        Architecture-Based 3D DenseNet with Person-Specific Normalization Using Neutral
        Expression for Spontaneous and Posed Smile Classification.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Siamese
        Architecture-Based 3D DenseNet with Person-Specific Normalization Using Neutral
        Expression for Spontaneous and Posed Smile Classification.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 20,
        no. 24 (2020): 7184.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 20,
        no. 24 (2020): 7184.","href":null}],"color":"default"}},{"object":"block","id":"91c6d21a-a576-408f-84b3-c3d4f0f8f43c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J3]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J3]","href":null},{"type":"text","text":{"content":"
        Nam, Uiseo, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Nam, Uiseo, ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Hyunwoong Ko, Jun-Young
        Lee, and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Hyunwoong Ko, Jun-Young Lee, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Analyzing
        facial and eye movements to screen for Alzheimer’s disease.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Analyzing
        facial and eye movements to screen for Alzheimer’s disease.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 20,
        no. 18 (2020): 5349.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 20,
        no. 18 (2020): 5349.","href":null}],"color":"default"}},{"object":"block","id":"0b07681e-f164-4ea6-8281-6283ab3cafc5","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J2]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J2]","href":null},{"type":"text","text":{"content":"
        Park, Seho, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Park, Seho, ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":" , Jae-A. Lim, Hyunwoong
        Ko, Taehoon Kim, Jung-In Lee, Hakrim Kim et al. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        , Jae-A. Lim, Hyunwoong Ko, Taehoon Kim, Jung-In Lee, Hakrim Kim et al. ","href":null},{"type":"text","text":{"content":"Differences
        in facial expressions between spontaneous and posed smiles: Automated method
        by action units and three-dimensional facial landmarks.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Differences
        in facial expressions between spontaneous and posed smiles: Automated method
        by action units and three-dimensional facial landmarks.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 20,
        no. 4 (2020): 1199.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 20,
        no. 4 (2020): 1199.","href":null}],"color":"default"}},{"object":"block","id":"eed6a270-afb2-46d4-96d2-f55207334fa0","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:54:00.000Z","last_edited_time":"2024-01-22T09:54:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2019","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2019","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"dd501c88-d17a-49fc-849f-af67b0261242","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J1]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J1]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Comparison
        of facial expression recognition performance according to the use of depth
        information of structured-light type RGB-D camera.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Comparison
        of facial expression recognition performance according to the use of depth
        information of structured-light type RGB-D camera.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Journal
        of Ambient Intelligence and Humanized Computing","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Journal
        of Ambient Intelligence and Humanized Computing","href":null},{"type":"text","text":{"content":" (2019):
        1-17.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" (2019):
        1-17.","href":null}],"color":"default"}},{"object":"block","id":"a2a72277-a364-4408-b353-7db4d11b6dda","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:55:00.000Z","last_edited_time":"2024-01-22T09:55:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2018","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2018","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"49b41686-435c-4b73-abdb-c7b828ace851","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[C1]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C1]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Comparison
        of 2D&3D Performances of Facial Feature Analysis Using RGB-D Vision Sensor.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Comparison
        of 2D&3D Performances of Facial Feature Analysis Using RGB-D Vision Sensor.","href":null},{"type":"text","text":{"content":"
        In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Advances in Computer Science
        and Ubiquitous Computing: CSA-CUTE 17","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Advances
        in Computer Science and Ubiquitous Computing: CSA-CUTE 17","href":null},{"type":"text","text":{"content":",
        pp. 1416-1421. Springer Singapore, 2018.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 1416-1421. Springer Singapore, 2018.","href":null}],"color":"default"}},{"object":"block","id":"f9a5e59e-583a-441f-83e3-b0b72a41c42a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:58:00.000Z","last_edited_time":"2024-01-22T10:02:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Domestic
        Journals (4건)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Domestic
        Journals (4건)","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"9eb80c95-ba75-403c-83e0-c5aca091c440","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:59:00.000Z","last_edited_time":"2024-01-25T04:17:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"황정원,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"황정원,
        ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"객체 추적 알고리즘 기반 비전 검사를
        통한 압출부 타겟 검출 방법\",","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"객체
        추적 알고리즘 기반 비전 검사를 통한 압출부 타겟 검출 방법\",","href":null},{"type":"text","text":{"content":"
        Journal of Next-generation Convergence Technology Association, 7(9), pp. 1412~1420,
        2023년 9월 (KCI)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Journal of Next-generation Convergence Technology Association, 7(9), pp. 1412~1420,
        2023년 9월 (KCI)","href":null}],"color":"default"}},{"object":"block","id":"5ee4343d-300b-4abb-ae3f-8249e66c4420","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:02:00.000Z","last_edited_time":"2024-01-25T04:17:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"이채원,
        윤성빈, 조철우, 황현상, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이채원,
        윤성빈, 조철우, 황현상, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"ESRGAN을 이용한 차량 번호판
        화질 개선을 통한 인식률 향상,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"ESRGAN을
        이용한 차량 번호판 화질 개선을 통한 인식률 향상,\"","href":null},{"type":"text","text":{"content":"
        Journal of Next-generation Convergence Technology Association, 6(1), pp. 5-11,
        2022년 1월.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Journal of Next-generation Convergence Technology Association, 6(1), pp. 5-11,
        2022년 1월.","href":null}],"color":"default"}},{"object":"block","id":"2c57197a-87c2-4740-a6e5-81d0f2b8f74c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:02:00.000Z","last_edited_time":"2024-01-25T04:17:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"안병선,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"안병선,
        ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"표정 정보를 보존하는 선택적 얼굴
        비식별화 방법,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"표정
        정보를 보존하는 선택적 얼굴 비식별화 방법,\"","href":null},{"type":"text","text":{"content":"
        Journal of Next-generation Convergence Technology Association, 6(11), pp.
        2103-2109, 2022년 11월.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Journal of Next-generation Convergence Technology Association, 6(11), pp.
        2103-2109, 2022년 11월.","href":null}],"color":"default"}},{"object":"block","id":"6ba2fbca-c434-4d13-ba5c-77ea62fcfb8f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:02:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"고대준,
        황현상, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"고대준,
        황현상, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김영원, 이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김영원, 이의철, ","href":null},{"type":"text","text":{"content":"\"RGB 카메라를 이용한
        다중 생체 신호 검출 통합 시스템 설계 및 개발,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"RGB
        카메라를 이용한 다중 생체 신호 검출 통합 시스템 설계 및 개발,\"","href":null},{"type":"text","text":{"content":"
        차세대융합기술학회논문지 제5권 제5호, pp. 749-756, 2021년 10월.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        차세대융합기술학회논문지 제5권 제5호, pp. 749-756, 2021년 10월.","href":null}],"color":"default"}},{"object":"block","id":"b4567eae-9241-4243-8254-a273ff37b497","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:59:00.000Z","last_edited_time":"2024-01-22T10:02:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Domestic
        conference (1건)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Domestic
        conference (1건)","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"91374006-eba4-43f9-8b84-4b555e24d343","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:03:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"이채원,
        윤성빈, 조철우, 황현상, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이채원,
        윤성빈, 조철우, 황현상, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"License plate image
        enhancement based on super-resolution Generative Adversarial Networks,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"License
        plate image enhancement based on super-resolution Generative Adversarial Networks,\"","href":null},{"type":"text","text":{"content":"
        제40회 한국법과학회 추계학술대회, 2021.11.23 ~ 2021.11.30, 온라인.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        제40회 한국법과학회 추계학술대회, 2021.11.23 ~ 2021.11.30, 온라인.","href":null}],"color":"default"}},{"object":"block","id":"f93d1848-c397-4e5b-acb0-e7a70ccbcd50","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:08:00.000Z","last_edited_time":"2024-01-22T10:08:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"66d69fc7-f30b-4a7c-90f7-5086c61785cb","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:08:00.000Z","last_edited_time":"2024-01-23T12:04:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Patents
        [","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Patents
        [","href":null},{"type":"text","text":{"content":"pr.smu.ac.kr","link":{"url":"https://pr.smu.ac.kr/property/%EB%93%B1%EB%A1%9D%ED%8A%B9%ED%97%88"}},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"pr.smu.ac.kr","href":"https://pr.smu.ac.kr/property/%EB%93%B1%EB%A1%9D%ED%8A%B9%ED%97%88"},{"type":"text","text":{"content":"]","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"07b31f67-a2ef-41ad-aeb3-9929e01f072f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:02:00.000Z","last_edited_time":"2024-01-23T12:03:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":"[R#]:
        Patent Registration, [A#]: Patent Application (#: Count)","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R#]:
        Patent Registration, [A#]: Patent Application (#: Count)","href":null}],"color":"default"}},{"object":"block","id":"ef54cb2e-3a58-4162-a7c9-44756521943a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T11:40:00.000Z","last_edited_time":"2024-01-23T11:40:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Patent
        Registration","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Patent
        Registration","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"2ef2cd0d-0528-4db5-904e-357fefe2581a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:15:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R5]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R5]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":"  and Lee, Eui Chul,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  and
        Lee, Eui Chul, ","href":null},{"type":"text","text":{"content":"“Method and
        apparatus for remote photoplethysmogram,”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Method
        and apparatus for remote photoplethysmogram,”","href":null},{"type":"text","text":{"content":"
        Korean Patent Registration No: 10-2542525-0000 Date: 2023.06.07","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-2542525-0000 Date: 2023.06.07","href":null}],"color":"default"}},{"object":"block","id":"768281a6-12d6-46a3-98c3-b6ab00b92bf1","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:32:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R4]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R4]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":";  Lee, E. C.; Nam,
        U.; Kim, Y; ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":";  Lee,
        E. C.; Nam, U.; Kim, Y; ","href":null},{"type":"text","text":{"content":"“Deivce
        and method of screening dementia through analysis between face direction and
        gaze,”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Deivce
        and method of screening dementia through analysis between face direction and
        gaze,”","href":null},{"type":"text","text":{"content":" Korean Patent Registration
        No: 10-2446848-0000 Date: 2022.09.20","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-2446848-0000 Date: 2022.09.20","href":null}],"color":"default"}},{"object":"block","id":"761c059d-ff59-487e-b374-afa38e86543d","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:32:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R3]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R3]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":";  Lee, E. C.; Kim,
        T.; Nam, U., ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":";  Lee,
        E. C.; Kim, T.; Nam, U., ","href":null},{"type":"text","text":{"content":"“Apparatus
        and method for measuring psychological anxiety”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Apparatus
        and method for measuring psychological anxiety”","href":null},{"type":"text","text":{"content":"
        Korean Patent Registration No: 10-2235932-0000 Date: 2021.03.30","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-2235932-0000 Date: 2021.03.30","href":null}],"color":"default"}},{"object":"block","id":"6d413977-dbee-465c-9c25-87fd52f6e9b3","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T11:34:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R2]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R2]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":"  and Lee, Eui Chul,,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  and
        Lee, Eui Chul,, ","href":null},{"type":"text","text":{"content":"“Apparatus
        and method for measuring face symmetry” ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Apparatus
        and method for measuring face symmetry” ","href":null},{"type":"text","text":{"content":"Korean
        Patent Registration No: 10-211515-00000 Date: 2020.05.20","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Korean
        Patent Registration No: 10-211515-00000 Date: 2020.05.20","href":null}],"color":"default"}},{"object":"block","id":"79cb76c5-e64c-4dfb-8f8e-2e7311b44412","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T11:38:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R1]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R1]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":"; Lee, E. C.; Kim,
        J. M., Jang, W., Han, J., ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":";
        Lee, E. C.; Kim, J. M., Jang, W., Han, J., ","href":null},{"type":"text","text":{"content":"“Apparatus
        and method for measuring heartbeat using triaxial accelerometer”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Apparatus
        and method for measuring heartbeat using triaxial accelerometer”","href":null},{"type":"text","text":{"content":"
        Korean Patent Registration No: 10-1986213-0000 Date: 2019.05.30","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-1986213-0000 Date: 2019.05.30","href":null}],"color":"default"}},{"object":"block","id":"ace6a29c-a063-45c2-aa87-f8238b69c368","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:08:00.000Z","last_edited_time":"2024-01-23T11:42:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Patent
        Application","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Patent
        Application","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"3e93bec6-8b1a-45c0-b223-40dea09c9da7","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A7]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A7]
        ","href":null},{"type":"text","text":{"content":"\"원격 심박수 측정을 위한 심박 신호를 선별하는
        방법 및 장치\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"원격
        심박수 측정을 위한 심박 신호를 선별하는 방법 및 장치\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2023-0059266, 출원일: 2023.05.08), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2023-0059266, 출원일: 2023.05.08), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김승현, 박신위, 안병선, 서현수)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김승현, 박신위, 안병선, 서현수)","href":null}],"color":"default"}},{"object":"block","id":"4175c1a1-0f11-4606-ad93-aa0d085ccbb4","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A6]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A6]
        ","href":null},{"type":"text","text":{"content":"\"다중 출력에 대한 표정 인식을 위한 뉴럴
        네트워크 모델의 경량화 장치 및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"다중
        출력에 대한 표정 인식을 위한 뉴럴 네트워크 모델의 경량화 장치 및 방법\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2023-0053584, 출원일: 2023.04.24), 발명자(이의철, 김승현, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2023-0053584, 출원일: 2023.04.24), 발명자(이의철, 김승현, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":")","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":")","href":null}],"color":"default"}},{"object":"block","id":"ef5fbc19-e47c-4887-80c3-19581e066324","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A5]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A5]
        ","href":null},{"type":"text","text":{"content":"\"심박수 산출 장치 및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"심박수
        산출 장치 및 방법\"","href":null},{"type":"text","text":{"content":", 국내특허출원 (출원번호:
        10-2023-0160496, 출원일: 2023.11.20), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2023-0160496, 출원일: 2023.11.20), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김승현, 전용권, 이지은, 이강인)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김승현, 전용권, 이지은, 이강인)","href":null}],"color":"default"}},{"object":"block","id":"95a7a2d2-37f7-48ae-9317-e94ac683ca19","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A4]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A4]
        ","href":null},{"type":"text","text":{"content":"\"원격 광용적맥파신호를 이용한 위조 얼굴 판별
        방법 및 장치\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"원격
        광용적맥파신호를 이용한 위조 얼굴 판별 방법 및 장치\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2022-0109832, 출원일: 2022.08.31), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2022-0109832, 출원일: 2022.08.31), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        유호준, 오재무)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        유호준, 오재무)","href":null}],"color":"default"}},{"object":"block","id":"7639a428-d00c-4d62-8d06-91d53270e7be","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A3]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A3]
        ","href":null},{"type":"text","text":{"content":"\"기계 학습 기반 시선 추적 장치 및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"기계
        학습 기반 시선 추적 장치 및 방법\"","href":null},{"type":"text","text":{"content":", 국내특허출원
        (출원번호: 10-2021-0045737, 출원일: 2021.04.08), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2021-0045737, 출원일: 2021.04.08), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        신유진, 한우정), 출원인(상명대학교산학협력단) (비대면)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        신유진, 한우정), 출원인(상명대학교산학협력단) (비대면)","href":null}],"color":"default"}},{"object":"block","id":"84919c4d-34a5-4b8c-990e-4e5de07d9d75","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A2]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A2]
        ","href":null},{"type":"text","text":{"content":"\"영상 인식 기반 지폐 일련번호 인식 장치
        및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"영상
        인식 기반 지폐 일련번호 인식 장치 및 방법\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2021-0016890, 출원일: 2021.02.05), 발명자(이의철, 장우혁, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2021-0016890, 출원일: 2021.02.05), 발명자(이의철, 장우혁, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        전수민, 석채린, 신광용, 이덕형, 김수미, 김상오)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        전수민, 석채린, 신광용, 이덕형, 김수미, 김상오)","href":null}],"color":"default"}},{"object":"block","id":"3802e76e-655e-4ea6-a428-96b15538fc49","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A1]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A1]
        ","href":null},{"type":"text","text":{"content":"\"얼굴표정 분석기반 자폐 스펙트럼 장애 평가
        방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"얼굴표정
        분석기반 자폐 스펙트럼 장애 평가 방법\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2020-0160142, 출원일: 2020.11.25), 발명자(이의철,","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2020-0160142, 출원일: 2020.11.25), 발명자(이의철,","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김영원)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김영원)","href":null}],"color":"default"}},{"object":"block","id":"940de8ef-f24a-47ed-ad6e-1193659c0422","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T06:57:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"90ede0fc-254a-4c9b-9632-ce2b2ac353a1","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T12:19:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Research
        Projects","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Research
        Projects","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"ded83e5a-ae10-44f2-90d0-8ef438195780","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T14:00:00.000Z","last_edited_time":"2024-01-25T03:13:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_2","heading_2":{"rich_text":[{"type":"text","text":{"content":"Grant","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Grant","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"b1c5cca3-e194-4338-ba34-dcd1524a190f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T14:47:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국연구재단","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국연구재단","href":null},{"type":"text","text":{"content":"(NRF)]
        비접촉 생체신호 추출 및 생체정보 융합을 통한 이상징후 판별 기술 개발,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(NRF)]
        비접촉 생체신호 추출 및 생체정보 융합을 통한 이상징후 판별 기술 개발,  ","href":null},{"type":"text","text":{"content":"Jul.
        2022 ~ Present\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jul.
        2022 ~ Present\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"과학기술정보통신부","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"과학기술정보통신부","href":null},{"type":"text","text":{"content":"(MSIT)]
        비접촉 생체신호 기반 운동효과 피드백 기능을 갖춘 AI 홈 트레이닝 시스템 제작,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(MSIT)]
        비접촉 생체신호 기반 운동효과 피드백 기능을 갖춘 AI 홈 트레이닝 시스템 제작,  ","href":null},{"type":"text","text":{"content":"Apr.
        2022 ~ Feb. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Apr.
        2022 ~ Feb. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"과학기술일자리진흥원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"과학기술일자리진흥원","href":null},{"type":"text","text":{"content":"(COMPA)]
        머신러닝 화재 판정 모듈 및 AI학습플랫폼 고도화.안정화 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(COMPA)]
        머신러닝 화재 판정 모듈 및 AI학습플랫폼 고도화.안정화 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager,  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager,  ","href":null},{"type":"text","text":{"content":"Oct. ","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Oct.
        ","href":null},{"type":"text","text":{"content":"2021 ~ ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2021
        ~ ","href":null},{"type":"text","text":{"content":"Mar. ","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        ","href":null},{"type":"text","text":{"content":"2023\n[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2023\n[","href":null},{"type":"text","text":{"content":"산업통상자원부","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"산업통상자원부","href":null},{"type":"text","text":{"content":"(KIAT)]
        안면인식 위변조 보안을 적용한 무인매장 솔루션 연구개발 및 실증,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(KIAT)]
        안면인식 위변조 보안을 적용한 무인매장 솔루션 연구개발 및 실증,  ","href":null},{"type":"text","text":{"content":"Sep.
        2021 ~ Aug. 2022\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sep.
        2021 ~ Aug. 2022\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국데이터산업진흥원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국데이터산업진흥원","href":null},{"type":"text","text":{"content":"(Kdata)]
        2021 데이터바우처 지원 사업(수요기관:기산전자), ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(Kdata)]
        2021 데이터바우처 지원 사업(수요기관:기산전자), ","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Jul. 2021 ~ Nov. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jul.
        2021 ~ Nov. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국전자기술연구원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국전자기술연구원","href":null},{"type":"text","text":{"content":"(KETI)]
        상태데이터 통합 인터페이스 제작,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(KETI)]
        상태데이터 통합 인터페이스 제작,  ","href":null},{"type":"text","text":{"content":"Oct.
        2020 ~ Dec. 2020\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Oct.
        2020 ~ Dec. 2020\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국연구재단","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국연구재단","href":null},{"type":"text","text":{"content":"(NRF)]
        카메라 기반 통합형 자율신경 반응 측정 모델 연구,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(NRF)]
        카메라 기반 통합형 자율신경 반응 측정 모델 연구,  ","href":null},{"type":"text","text":{"content":"Jun.
        2019 ~ Feb. 2022\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jun.
        2019 ~ Feb. 2022\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국연구재단","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국연구재단","href":null},{"type":"text","text":{"content":"(NRF)]
        생체기반 영상정보 정량적 분석 시스템,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(NRF)]
        생체기반 영상정보 정량적 분석 시스템,  ","href":null},{"type":"text","text":{"content":"Mar.
        2017 ~ Feb. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2017 ~ Feb. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"산업통상자원부","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"산업통상자원부","href":null},{"type":"text","text":{"content":"(MOTIE)]
        마음-몸 피드백을 통한 감정 치유를 위한 비접촉식 센싱 기반 인간 내면상태 인식 및 미러링 표출 상호작용 로봇 기술 개발,","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(MOTIE)]
        마음-몸 피드백을 통한 감정 치유를 위한 비접촉식 센싱 기반 인간 내면상태 인식 및 미러링 표출 상호작용 로봇 기술 개발,","href":null},{"type":"text","text":{"content":"  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  ","href":null},{"type":"text","text":{"content":"Mar.
        2017 ~ Aug. 2021","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2017 ~ Aug. 2021","href":null}],"color":"default"}},{"object":"block","id":"b478982e-fc4f-4cca-8e12-753972b3c6aa","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T13:12:00.000Z","last_edited_time":"2024-01-25T03:13:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Contract","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Contract","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"27b78492-10f3-4725-b428-03dd15919b81","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T14:14:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"현대엔지비주식회사","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"현대엔지비주식회사","href":null},{"type":"text","text":{"content":"(HYUNDAI
        NGV)] 비전 기반 심박수 측정 시스템 개발 및 고도화, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(HYUNDAI
        NGV)] 비전 기반 심박수 측정 시스템 개발 및 고도화, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",","href":null},{"type":"text","text":{"content":"  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  ","href":null},{"type":"text","text":{"content":"Jul.
        2023 ~ Oct. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jul.
        2023 ~ Oct. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"현대엔지비주식회사","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"현대엔지비주식회사","href":null},{"type":"text","text":{"content":"(HYUNDAI
        NGV)] 운전자 감성인식을 위한 비접촉 생체신호 측정기술 개발 ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(HYUNDAI
        NGV)] 운전자 감성인식을 위한 비접촉 생체신호 측정기술 개발 ","href":null},{"type":"text","text":{"content":"Project
        Manager,  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager,  ","href":null},{"type":"text","text":{"content":"Oct. 2022 ~ Sep.
        2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Oct.
        2022 ~ Sep. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"이후시스","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이후시스","href":null},{"type":"text","text":{"content":"(주)]
        비접촉 생체반응 측정 기술 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(주)]
        비접촉 생체반응 측정 기술 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Aug.
        2022 ~ Jan. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Aug.
        2022 ~ Jan. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"에스엘주식회사
        진량공장","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"에스엘주식회사
        진량공장","href":null},{"type":"text","text":{"content":"(SL Corporation)] 얼굴
        표정 및 HRV 특징을 이용한 운전자 감정인식 알고리즘 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(SL
        Corporation)] 얼굴 표정 및 HRV 특징을 이용한 운전자 감정인식 알고리즘 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Jun.
        2022 ~ Dec. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jun.
        2022 ~ Dec. 2023\n","href":null},{"type":"text","text":{"content":"[(주)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[(주)","href":null},{"type":"text","text":{"content":"이모코그","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이모코그","href":null},{"type":"text","text":{"content":"]
        신경퇴행성 질환자의 생체신호 수집 및 분석 기술 개발,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]
        신경퇴행성 질환자의 생체신호 수집 및 분석 기술 개발,  ","href":null},{"type":"text","text":{"content":"Mar.
        2022 ~ Aug. 2022\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2022 ~ Aug. 2022\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"현대엔지비주식회사","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"현대엔지비주식회사","href":null},{"type":"text","text":{"content":"(HYUNDAI
        NGV)] 비전기반 생체반응 및 행동상태 측정 연구,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(HYUNDAI
        NGV)] 비전기반 생체반응 및 행동상태 측정 연구,  ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",","href":null},{"type":"text","text":{"content":"  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  ","href":null},{"type":"text","text":{"content":"Dec.
        2021 ~ Dec. 2022\n[주식회사 ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Dec.
        2021 ~ Dec. 2022\n[주식회사 ","href":null},{"type":"text","text":{"content":"애니랙티브","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"애니랙티브","href":null},{"type":"text","text":{"content":"]
        RGB 카메라 기반 생리반응 측정 및 인터렉션 기술개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]
        RGB 카메라 기반 생리반응 측정 및 인터렉션 기술개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Aug.
        2021 ~ Oct. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Aug.
        2021 ~ Oct. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국전자기술연구원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국전자기술연구원","href":null},{"type":"text","text":{"content":"(KETI)]
        상태데이터 통합 인터페이스 고도화 용역,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(KETI)]
        상태데이터 통합 인터페이스 고도화 용역,  ","href":null},{"type":"text","text":{"content":"Jun.
        2021 ~ Nov. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jun.
        2021 ~ Nov. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"대검찰청","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"대검찰청","href":null},{"type":"text","text":{"content":"(SPO)]
        AI를 이용한 차량번호 인식 기법 연구, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(SPO)]
        AI를 이용한 차량번호 인식 기법 연구, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Mar.
        2021 ~ Dec. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2021 ~ Dec. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"기산전자","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"기산전자","href":null},{"type":"text","text":{"content":"]
        Deep Learning 기반 PC OCR 엔진 기술 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]
        Deep Learning 기반 PC OCR 엔진 기술 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager,  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager,  ","href":null},{"type":"text","text":{"content":"Mar. 2020 ~ Jun.
        2020","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2020 ~ Jun. 2020","href":null}],"color":"default"}},{"object":"block","id":"0b21e1e9-777e-4a67-ab43-16a5cf550402","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T06:57:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"5222fc28-9b1d-4283-84cb-f018a9dc81f4","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:46:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Demo(youtube)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Demo(youtube)","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"c0ee80ca-1517-45f0-962d-b690d44da8c1","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:46:00.000Z","last_edited_time":"2024-01-25T04:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Remote
        Photoplethysmography","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Remote
        Photoplethysmography","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"640641ed-1e3d-4dde-aa36-9dca0f6c7a90","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:47:00.000Z","last_edited_time":"2024-01-25T04:48:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Real-time
        skin segmentation-based remote photoplethysmography","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Real-time
        skin segmentation-based remote photoplethysmography","href":null}],"type":"external","external":{"url":"https://youtu.be/n_agiICg5PQ?si=rWAUoqZ8OjPWojeV"}}},{"object":"block","id":"70395474-0fec-4b17-8e67-b850398c74ca","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:48:00.000Z","last_edited_time":"2024-01-25T04:48:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Application
        of the implemented real-time rPPG signal processing for driver monitoring","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Application
        of the implemented real-time rPPG signal processing for driver monitoring","href":null}],"type":"external","external":{"url":"https://youtu.be/Y4lsUkucfks?si=h9FIschSkHi1ZjEq"}}},{"object":"block","id":"977f9c94-9d4c-4c47-939a-433ab3399f97","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[],"color":"default"}},{"object":"block","id":"c1e0c9eb-40bc-461f-b940-299df7653d9f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Gaze
        Analysis","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Gaze
        Analysis","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"21fa32be-64bc-4614-9e65-ae900e835dbf","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:49:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Infrared
        camera-based gaze tracking with 4-point calibration","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Infrared
        camera-based gaze tracking with 4-point calibration","href":null}],"type":"external","external":{"url":"https://youtu.be/cMd2WTIpTWA?si=EQNGDvuQ-ZAfG45j"}}},{"object":"block","id":"2acb729c-781d-4c2e-8899-8bef00264277","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:50:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Facial
        behavior analysis based on face and eye landmarks.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Facial
        behavior analysis based on face and eye landmarks.","href":null}],"type":"external","external":{"url":"https://youtu.be/1uOyHijAFpQ?si=uT9DITi--88CRc9J"}}},{"object":"block","id":"918d086e-86e3-4c36-972b-55128985bd6d","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:50:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[],"color":"default"}}],"next_cursor":null,"has_more":false,"type":"block","block":{},"request_id":"55953994-83c4-4a48-9dd8-bba0a4ee7c06"}'
  recorded_at: Thu, 25 Jan 2024 05:16:50 GMT
- request:
    method: get
    uri: https://api.notion.com/v1/pages/838177043c474405bcbc09826a13153b
    body:
      encoding: US-ASCII
      string: ''
    headers:
      Accept:
      - application/json; charset=utf-8
      User-Agent:
      - Notion Ruby Client/1.2.2
      Authorization:
      - Bearer <NOTION_TOKEN>
      Notion-Version:
      - '2022-02-22'
  response:
    status:
      code: 200
      message: OK
    headers:
      date:
      - Thu, 25 Jan 2024 05:16:51 GMT
      content-type:
      - application/json; charset=utf-8
      transfer-encoding:
      - chunked
      connection:
      - keep-alive
      x-powered-by:
      - Express
      x-notion-request-id:
      - 13e192ef-e9c6-4fab-8ad6-821d5459f297
      etag:
      - W/"5ff-SO4xFzvwUlaWs/ccyrTIXrjqaeo"
      vary:
      - Accept-Encoding
      content-encoding:
      - gzip
      cf-cache-status:
      - DYNAMIC
      set-cookie:
      - __cf_bm=dULJIm1FJNkdPFosTdGFE8dAaNQ7nf6y9Adk0SBUgBk-1706159811-1-AbnY/1ldm7BcqBQlLzgVviDPVjMN3YhJJdsdf2UySxdNgtDMnUUoyx9L4/gjFJDL1aYLHKY5kmb0rQ1PWDGaT+s=;
        path=/; expires=Thu, 25-Jan-24 05:46:51 GMT; domain=.notion.com; HttpOnly;
        Secure; SameSite=None
      server:
      - cloudflare
      cf-ray:
      - 84ae0be20ad130ce-ICN
    body:
      encoding: UTF-8
      string: '{"object":"page","id":"83817704-3c47-4405-bcbc-09826a13153b","created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"cover":null,"icon":{"type":"file","file":{"url":"https://prod-files-secure.s3.us-west-2.amazonaws.com/5758ba68-cfd2-4a36-b622-fe9551804f02/1d07fa7e-bc25-445b-8981-85b6fd1baa2e/%E1%84%8E%E1%85%B1%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%28%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45HZZMZUHI%2F20240125%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20240125T051651Z&X-Amz-Expires=3600&X-Amz-Signature=faa85d9f7df57f7b644fd59776f0394216fe6a716c445a05a75698f0daa9ee9c&X-Amz-SignedHeaders=host&x-id=GetObject","expiry_time":"2024-01-25T06:16:50.995Z"}},"parent":{"type":"workspace","workspace":true},"archived":false,"properties":{"title":{"id":"title","type":"title","title":[{"type":"text","text":{"content":"CV","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"CV","href":null}]}},"url":"https://www.notion.so/CV-838177043c474405bcbc09826a13153b","public_url":"https://organized-manchego-5df.notion.site/CV-838177043c474405bcbc09826a13153b","request_id":"13e192ef-e9c6-4fab-8ad6-821d5459f297"}'
  recorded_at: Thu, 25 Jan 2024 05:16:51 GMT
- request:
    method: get
    uri: https://api.notion.com/v1/blocks/838177043c474405bcbc09826a13153b/children
    body:
      encoding: US-ASCII
      string: ''
    headers:
      Accept:
      - application/json; charset=utf-8
      User-Agent:
      - Notion Ruby Client/1.2.2
      Authorization:
      - Bearer <NOTION_TOKEN>
      Notion-Version:
      - '2022-02-22'
  response:
    status:
      code: 200
      message: OK
    headers:
      date:
      - Thu, 25 Jan 2024 05:16:51 GMT
      content-type:
      - application/json; charset=utf-8
      transfer-encoding:
      - chunked
      connection:
      - keep-alive
      x-powered-by:
      - Express
      x-notion-request-id:
      - 50b93ea1-fe77-4c1a-8d37-0e83def88744
      etag:
      - W/"1d348-t1Y0ylBOCjAvprTnUj6u4HqzDak"
      vary:
      - Accept-Encoding
      content-encoding:
      - gzip
      cf-cache-status:
      - DYNAMIC
      set-cookie:
      - __cf_bm=X7fNLDrU4eyl3Euw0xRrIk6xBuQZP2PFZBbuq.G_ACM-1706159811-1-AewkF4pKjZGGE7wWCtgdYJtmU2zJTZamjqQxyrl+dGYOB0t6tMJGnfaFbzNUzYZ6JvBBq1lcL07RtHmZGKYd158=;
        path=/; expires=Thu, 25-Jan-24 05:46:51 GMT; domain=.notion.com; HttpOnly;
        Secure; SameSite=None
      server:
      - cloudflare
      cf-ray:
      - 84ae0be36f7730af-ICN
    body:
      encoding: UTF-8
      string: '{"object":"list","results":[{"object":"block","id":"2750c0c7-0478-4f5f-8b45-28524c14b363","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T16:34:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[],"color":"gray"}},{"object":"block","id":"603e3160-8dc0-4f49-911a-352d804f0beb","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T06:57:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"37b57799-74c7-437f-bd5b-15dce854a8ef","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T10:16:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Biography","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Biography","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"8ce6a98a-50ad-4a10-8e60-86dd9cb0bdd2","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T07:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":"I
        work on overcoming instability and noisy data of Affective computing in the
        wild setting. Throughout my research, I have studied various kinds of topics
        to help AI deal with real-world problems in emotion recognition. Specifically,
        I am interested in advancing AI to better inference facial expression recognition
        and physiological signal sensing, such as in remote photoplethysmography and
        breathing rate.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"I
        work on overcoming instability and noisy data of Affective computing in the
        wild setting. Throughout my research, I have studied various kinds of topics
        to help AI deal with real-world problems in emotion recognition. Specifically,
        I am interested in advancing AI to better inference facial expression recognition
        and physiological signal sensing, such as in remote photoplethysmography and
        breathing rate.","href":null}],"color":"gray"}},{"object":"block","id":"fc71547c-5266-4539-b627-60924852026c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:06:00.000Z","last_edited_time":"2024-01-22T08:07:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":true,"archived":false,"type":"column_list","column_list":{}},{"object":"block","id":"cb3f9816-a972-4e00-9ad1-7ef0c5fa9359","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T16:34:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"a65d9784-a50b-4f27-b7aa-38c735c538c3","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T16:34:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Publications
        [","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Publications
        [","href":null},{"type":"text","text":{"content":"Google Scholar Profile","link":{"url":"https://scholar.google.co.kr/citations?user=lU9NpJUAAAAJ&hl=en"}},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Google
        Scholar Profile","href":"https://scholar.google.co.kr/citations?user=lU9NpJUAAAAJ&hl=en"},{"type":"text","text":{"content":"]","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"0f8e0098-ce7a-46f8-9667-caea1a3c4301","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:26:00.000Z","last_edited_time":"2024-01-22T09:56:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":"[C#]:
        Conference, [J#]: Journal, [W#]: workshops (#: Count)","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C#]:
        Conference, [J#]: Journal, [W#]: workshops (#: Count)","href":null}],"color":"default"}},{"object":"block","id":"e0296776-1f89-45c3-b917-7f05ca8e29f7","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T08:44:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2023","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2023","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"20efdfe3-0877-4dbf-a50b-80c0bbe8d9e6","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:47:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J11]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J11]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Jaemu Oh, Hojoon You,
        and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Jaemu Oh, Hojoon You, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Improving
        Remote Photoplethysmography Performance through Deep-Learning-Based Real-Time
        Skin Segmentation Network.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Improving
        Remote Photoplethysmography Performance through Deep-Learning-Based Real-Time
        Skin Segmentation Network.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Electronics","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Electronics","href":null},{"type":"text","text":{"content":" 12,
        no. 17 (2023): 3729.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 12,
        no. 17 (2023): 3729.","href":null}],"color":"default"}},{"object":"block","id":"6dc864c9-bfcc-4921-a9d0-5747d2839d52","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:57:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J10]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J10]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Seunghyun Kim, Byeongseon
        An, Hyunsoo Seo, Shinwi Park, and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Seunghyun Kim, Byeongseon An, Hyunsoo Seo, Shinwi Park, and Eui Chul Lee.
        ","href":null},{"type":"text","text":{"content":"Noise-Assessment-Based Screening
        Method for Remote Photoplethysmography Estimation.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Noise-Assessment-Based
        Screening Method for Remote Photoplethysmography Estimation.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Applied
        Sciences","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Applied
        Sciences","href":null},{"type":"text","text":{"content":" 13, no. 17 (2023):
        9818.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 13,
        no. 17 (2023): 9818.","href":null}],"color":"default"}},{"object":"block","id":"e0354384-3f62-4bcb-95b1-3e16c21fe867","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:57:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J9]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J9]","href":null},{"type":"text","text":{"content":"
        Jin, Eunju, Hyunju Kang, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Jin, Eunju, Hyunju Kang, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Seung Gun Lee, and Eui
        Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Seung Gun Lee, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Analysis
        of Nursing Students’ Nonverbal Communication Patterns during Simulation Practice:
        A Pilot Study.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Analysis
        of Nursing Students’ Nonverbal Communication Patterns during Simulation Practice:
        A Pilot Study.","href":null},{"type":"text","text":{"content":" In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Healthcare","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Healthcare","href":null},{"type":"text","text":{"content":",
        vol. 11, no. 16, p. 2335. MDPI, 2023.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        vol. 11, no. 16, p. 2335. MDPI, 2023.","href":null}],"color":"default"}},{"object":"block","id":"8edbf65d-e1fb-4a5e-9711-beaeeb34453a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T08:59:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J8]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J8]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Seunghyun Kim, and Eui
        Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Seunghyun Kim, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Fast
        and Accurate Facial Expression Image Classification and Regression Method
        Based on Knowledge Distillation.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Fast
        and Accurate Facial Expression Image Classification and Regression Method
        Based on Knowledge Distillation.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Applied
        Sciences","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Applied
        Sciences","href":null},{"type":"text","text":{"content":" 13, no. 11 (2023):
        6409.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 13,
        no. 11 (2023): 6409.","href":null}],"color":"default"}},{"object":"block","id":"c7e54347-e379-4ef5-af9d-352ace4dcc90","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J7]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J7]","href":null},{"type":"text","text":{"content":"
        You, Hojoon, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        You, Hojoon, ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Jaemu Oh, and Eui Chul
        Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Jaemu Oh, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Efficient
        and Low Color Information Dependency Skin Segmentation Model.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Efficient
        and Low Color Information Dependency Skin Segmentation Model.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Mathematics","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mathematics","href":null},{"type":"text","text":{"content":" 11,
        no. 9 (2023): 2057.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 11,
        no. 9 (2023): 2057.","href":null}],"color":"default"}},{"object":"block","id":"315dcba4-0eb8-4294-b3ff-9840315cf22c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[W1]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[W1]","href":null},{"type":"text","text":{"content":"
        Kim, Seunghyun, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Kim, Seunghyun, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Multi-View
        Body Image-Based Prediction of Body Mass Index and Various Body Part Sizes.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Multi-View
        Body Image-Based Prediction of Body Mass Index and Various Body Part Sizes.","href":null},{"type":"text","text":{"content":"
        In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Proceedings of the IEEE/CVF
        Conference on Computer Vision and Pattern Recognition","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Proceedings
        of the IEEE/CVF Conference on Computer Vision and Pattern Recognition","href":null},{"type":"text","text":{"content":",
        pp. 6033-6040. 2023.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 6033-6040. 2023.","href":null}],"color":"default"}},{"object":"block","id":"e14de6ab-ccdb-47e2-b798-33052a72a411","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:06:00.000Z","last_edited_time":"2024-01-22T09:06:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2022","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2022","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"759382ef-a770-48d7-9040-917c78415e80","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:01:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J6]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J6]","href":null},{"type":"text","text":{"content":"
        Hwang, Hyeonsang, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Hwang, Hyeonsang, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"A real-time
        remote respiration measurement method with improved robustness based on a
        CNN model.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"A
        real-time remote respiration measurement method with improved robustness based
        on a CNN model.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Applied
        Sciences","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Applied
        Sciences","href":null},{"type":"text","text":{"content":" 12, no. 22 (2022):
        11603.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 12,
        no. 22 (2022): 11603.","href":null}],"color":"default"}},{"object":"block","id":"46170dbf-5306-47dd-be6a-25bb36296b4c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-22T10:06:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J5]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J5]","href":null},{"type":"text","text":{"content":"
        Jang, Woohyuk, Chaewon Lee, Dae Sik Jeong, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Jang, Woohyuk, Chaewon Lee, Dae Sik Jeong, ","href":null},{"type":"text","text":{"content":"Kunyoung
        Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Multi-Currency
        Integrated Serial Number Recognition Model of Images Acquired by Banknote
        Counters.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Multi-Currency
        Integrated Serial Number Recognition Model of Images Acquired by Banknote
        Counters.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 22,
        no. 22 (2022): 8612.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 22,
        no. 22 (2022): 8612.","href":null}],"color":"default"}},{"object":"block","id":"d2a9abd2-5e89-4cce-8181-8fa2e22360ac","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[C3]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C3]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Hojoon You, Jaemu Oh,
        and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Hojoon You, Jaemu Oh, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Extremely
        Lightweight Skin Segmentation Networks to Improve Remote Photoplethysmography
        Measurement.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Extremely
        Lightweight Skin Segmentation Networks to Improve Remote Photoplethysmography
        Measurement.","href":null},{"type":"text","text":{"content":" In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"International Conference
        on Intelligent Human Computer Interaction","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"International
        Conference on Intelligent Human Computer Interaction","href":null},{"type":"text","text":{"content":",
        pp. 454-459. Cham: Springer Nature Switzerland, 2022.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 454-459. Cham: Springer Nature Switzerland, 2022.","href":null}],"color":"default"}},{"object":"block","id":"a75770e6-fa9b-40e2-b4b1-260c7221b092","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:53:00.000Z","last_edited_time":"2024-01-22T09:53:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2021","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2021","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"0bdf295e-9cb0-4dc0-b7e4-81f10764eded","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[C2]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C2]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Kyungwon Jin, Youngwon
        Kim, Jee Hang Lee, and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Kyungwon Jin, Youngwon Kim, Jee Hang Lee, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"A
        comparative analysis on the impact of face tracker and skin segmentation onto
        improving the performance of real-time remote photoplethysmography.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"A
        comparative analysis on the impact of face tracker and skin segmentation onto
        improving the performance of real-time remote photoplethysmography.","href":null},{"type":"text","text":{"content":"
        In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Intelligent Human Computer
        Interaction: 12th International Conference, IHCI 2020, Daegu, South Korea,
        November 24–26, 2020, Proceedings, Part II 12","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Intelligent
        Human Computer Interaction: 12th International Conference, IHCI 2020, Daegu,
        South Korea, November 24–26, 2020, Proceedings, Part II 12","href":null},{"type":"text","text":{"content":",
        pp. 27-37. Springer International Publishing, 2021.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 27-37. Springer International Publishing, 2021.","href":null}],"color":"default"}},{"object":"block","id":"66557549-d03e-4ced-9f37-7c7bf54cdb78","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:53:00.000Z","last_edited_time":"2024-01-22T09:53:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2020","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2020","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"8f3bafe7-dff4-4074-af3d-5e330921434f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J4]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J4]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Siamese
        Architecture-Based 3D DenseNet with Person-Specific Normalization Using Neutral
        Expression for Spontaneous and Posed Smile Classification.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Siamese
        Architecture-Based 3D DenseNet with Person-Specific Normalization Using Neutral
        Expression for Spontaneous and Posed Smile Classification.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 20,
        no. 24 (2020): 7184.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 20,
        no. 24 (2020): 7184.","href":null}],"color":"default"}},{"object":"block","id":"91c6d21a-a576-408f-84b3-c3d4f0f8f43c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J3]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J3]","href":null},{"type":"text","text":{"content":"
        Nam, Uiseo, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Nam, Uiseo, ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", Hyunwoong Ko, Jun-Young
        Lee, and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        Hyunwoong Ko, Jun-Young Lee, and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Analyzing
        facial and eye movements to screen for Alzheimer’s disease.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Analyzing
        facial and eye movements to screen for Alzheimer’s disease.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 20,
        no. 18 (2020): 5349.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 20,
        no. 18 (2020): 5349.","href":null}],"color":"default"}},{"object":"block","id":"0b07681e-f164-4ea6-8281-6283ab3cafc5","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J2]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J2]","href":null},{"type":"text","text":{"content":"
        Park, Seho, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Park, Seho, ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":" , Jae-A. Lim, Hyunwoong
        Ko, Taehoon Kim, Jung-In Lee, Hakrim Kim et al. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        , Jae-A. Lim, Hyunwoong Ko, Taehoon Kim, Jung-In Lee, Hakrim Kim et al. ","href":null},{"type":"text","text":{"content":"Differences
        in facial expressions between spontaneous and posed smiles: Automated method
        by action units and three-dimensional facial landmarks.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Differences
        in facial expressions between spontaneous and posed smiles: Automated method
        by action units and three-dimensional facial landmarks.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Sensors","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sensors","href":null},{"type":"text","text":{"content":" 20,
        no. 4 (2020): 1199.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" 20,
        no. 4 (2020): 1199.","href":null}],"color":"default"}},{"object":"block","id":"eed6a270-afb2-46d4-96d2-f55207334fa0","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:54:00.000Z","last_edited_time":"2024-01-22T09:54:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2019","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2019","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"dd501c88-d17a-49fc-849f-af67b0261242","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[J1]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[J1]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Comparison
        of facial expression recognition performance according to the use of depth
        information of structured-light type RGB-D camera.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Comparison
        of facial expression recognition performance according to the use of depth
        information of structured-light type RGB-D camera.","href":null},{"type":"text","text":{"content":" ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" ","href":null},{"type":"text","text":{"content":"Journal
        of Ambient Intelligence and Humanized Computing","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Journal
        of Ambient Intelligence and Humanized Computing","href":null},{"type":"text","text":{"content":" (2019):
        1-17.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":" (2019):
        1-17.","href":null}],"color":"default"}},{"object":"block","id":"a2a72277-a364-4408-b353-7db4d11b6dda","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:55:00.000Z","last_edited_time":"2024-01-22T09:55:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"2018","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2018","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"49b41686-435c-4b73-abdb-c7b828ace851","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:03:00.000Z","last_edited_time":"2024-01-25T04:20:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[C1]","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[C1]","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Kunyoung Lee","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Kunyoung
        Lee","href":null},{"type":"text","text":{"content":", and Eui Chul Lee. ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        and Eui Chul Lee. ","href":null},{"type":"text","text":{"content":"Comparison
        of 2D&3D Performances of Facial Feature Analysis Using RGB-D Vision Sensor.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Comparison
        of 2D&3D Performances of Facial Feature Analysis Using RGB-D Vision Sensor.","href":null},{"type":"text","text":{"content":"
        In ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        In ","href":null},{"type":"text","text":{"content":"Advances in Computer Science
        and Ubiquitous Computing: CSA-CUTE 17","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Advances
        in Computer Science and Ubiquitous Computing: CSA-CUTE 17","href":null},{"type":"text","text":{"content":",
        pp. 1416-1421. Springer Singapore, 2018.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        pp. 1416-1421. Springer Singapore, 2018.","href":null}],"color":"default"}},{"object":"block","id":"f9a5e59e-583a-441f-83e3-b0b72a41c42a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:58:00.000Z","last_edited_time":"2024-01-22T10:02:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Domestic
        Journals (4건)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Domestic
        Journals (4건)","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"9eb80c95-ba75-403c-83e0-c5aca091c440","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:59:00.000Z","last_edited_time":"2024-01-25T04:17:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"황정원,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"황정원,
        ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"객체 추적 알고리즘 기반 비전 검사를
        통한 압출부 타겟 검출 방법\",","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"객체
        추적 알고리즘 기반 비전 검사를 통한 압출부 타겟 검출 방법\",","href":null},{"type":"text","text":{"content":"
        Journal of Next-generation Convergence Technology Association, 7(9), pp. 1412~1420,
        2023년 9월 (KCI)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Journal of Next-generation Convergence Technology Association, 7(9), pp. 1412~1420,
        2023년 9월 (KCI)","href":null}],"color":"default"}},{"object":"block","id":"5ee4343d-300b-4abb-ae3f-8249e66c4420","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:02:00.000Z","last_edited_time":"2024-01-25T04:17:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"이채원,
        윤성빈, 조철우, 황현상, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이채원,
        윤성빈, 조철우, 황현상, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"ESRGAN을 이용한 차량 번호판
        화질 개선을 통한 인식률 향상,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"ESRGAN을
        이용한 차량 번호판 화질 개선을 통한 인식률 향상,\"","href":null},{"type":"text","text":{"content":"
        Journal of Next-generation Convergence Technology Association, 6(1), pp. 5-11,
        2022년 1월.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Journal of Next-generation Convergence Technology Association, 6(1), pp. 5-11,
        2022년 1월.","href":null}],"color":"default"}},{"object":"block","id":"2c57197a-87c2-4740-a6e5-81d0f2b8f74c","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:02:00.000Z","last_edited_time":"2024-01-25T04:17:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"안병선,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"안병선,
        ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"표정 정보를 보존하는 선택적 얼굴
        비식별화 방법,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"표정
        정보를 보존하는 선택적 얼굴 비식별화 방법,\"","href":null},{"type":"text","text":{"content":"
        Journal of Next-generation Convergence Technology Association, 6(11), pp.
        2103-2109, 2022년 11월.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Journal of Next-generation Convergence Technology Association, 6(11), pp.
        2103-2109, 2022년 11월.","href":null}],"color":"default"}},{"object":"block","id":"6ba2fbca-c434-4d13-ba5c-77ea62fcfb8f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:02:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"고대준,
        황현상, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"고대준,
        황현상, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김영원, 이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김영원, 이의철, ","href":null},{"type":"text","text":{"content":"\"RGB 카메라를 이용한
        다중 생체 신호 검출 통합 시스템 설계 및 개발,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"RGB
        카메라를 이용한 다중 생체 신호 검출 통합 시스템 설계 및 개발,\"","href":null},{"type":"text","text":{"content":"
        차세대융합기술학회논문지 제5권 제5호, pp. 749-756, 2021년 10월.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        차세대융합기술학회논문지 제5권 제5호, pp. 749-756, 2021년 10월.","href":null}],"color":"default"}},{"object":"block","id":"b4567eae-9241-4243-8254-a273ff37b497","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T09:59:00.000Z","last_edited_time":"2024-01-22T10:02:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Domestic
        conference (1건)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Domestic
        conference (1건)","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"91374006-eba4-43f9-8b84-4b555e24d343","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:03:00.000Z","last_edited_time":"2024-01-25T04:18:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"이채원,
        윤성빈, 조철우, 황현상, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이채원,
        윤성빈, 조철우, 황현상, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        이의철, ","href":null},{"type":"text","text":{"content":"\"License plate image
        enhancement based on super-resolution Generative Adversarial Networks,\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"License
        plate image enhancement based on super-resolution Generative Adversarial Networks,\"","href":null},{"type":"text","text":{"content":"
        제40회 한국법과학회 추계학술대회, 2021.11.23 ~ 2021.11.30, 온라인.","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        제40회 한국법과학회 추계학술대회, 2021.11.23 ~ 2021.11.30, 온라인.","href":null}],"color":"default"}},{"object":"block","id":"f93d1848-c397-4e5b-acb0-e7a70ccbcd50","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:08:00.000Z","last_edited_time":"2024-01-22T10:08:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"66d69fc7-f30b-4a7c-90f7-5086c61785cb","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:08:00.000Z","last_edited_time":"2024-01-23T12:04:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Patents
        [","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Patents
        [","href":null},{"type":"text","text":{"content":"pr.smu.ac.kr","link":{"url":"https://pr.smu.ac.kr/property/%EB%93%B1%EB%A1%9D%ED%8A%B9%ED%97%88"}},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"pr.smu.ac.kr","href":"https://pr.smu.ac.kr/property/%EB%93%B1%EB%A1%9D%ED%8A%B9%ED%97%88"},{"type":"text","text":{"content":"]","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"07b31f67-a2ef-41ad-aeb3-9929e01f072f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:02:00.000Z","last_edited_time":"2024-01-23T12:03:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[{"type":"text","text":{"content":"[R#]:
        Patent Registration, [A#]: Patent Application (#: Count)","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R#]:
        Patent Registration, [A#]: Patent Application (#: Count)","href":null}],"color":"default"}},{"object":"block","id":"ef54cb2e-3a58-4162-a7c9-44756521943a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T11:40:00.000Z","last_edited_time":"2024-01-23T11:40:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Patent
        Registration","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Patent
        Registration","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"2ef2cd0d-0528-4db5-904e-357fefe2581a","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:15:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R5]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R5]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":"  and Lee, Eui Chul,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  and
        Lee, Eui Chul, ","href":null},{"type":"text","text":{"content":"“Method and
        apparatus for remote photoplethysmogram,”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Method
        and apparatus for remote photoplethysmogram,”","href":null},{"type":"text","text":{"content":"
        Korean Patent Registration No: 10-2542525-0000 Date: 2023.06.07","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-2542525-0000 Date: 2023.06.07","href":null}],"color":"default"}},{"object":"block","id":"768281a6-12d6-46a3-98c3-b6ab00b92bf1","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:32:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R4]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R4]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":";  Lee, E. C.; Nam,
        U.; Kim, Y; ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":";  Lee,
        E. C.; Nam, U.; Kim, Y; ","href":null},{"type":"text","text":{"content":"“Deivce
        and method of screening dementia through analysis between face direction and
        gaze,”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Deivce
        and method of screening dementia through analysis between face direction and
        gaze,”","href":null},{"type":"text","text":{"content":" Korean Patent Registration
        No: 10-2446848-0000 Date: 2022.09.20","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-2446848-0000 Date: 2022.09.20","href":null}],"color":"default"}},{"object":"block","id":"761c059d-ff59-487e-b374-afa38e86543d","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:32:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R3]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R3]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":";  Lee, E. C.; Kim,
        T.; Nam, U., ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":";  Lee,
        E. C.; Kim, T.; Nam, U., ","href":null},{"type":"text","text":{"content":"“Apparatus
        and method for measuring psychological anxiety”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Apparatus
        and method for measuring psychological anxiety”","href":null},{"type":"text","text":{"content":"
        Korean Patent Registration No: 10-2235932-0000 Date: 2021.03.30","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-2235932-0000 Date: 2021.03.30","href":null}],"color":"default"}},{"object":"block","id":"6d413977-dbee-465c-9c25-87fd52f6e9b3","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T11:34:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R2]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R2]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":"  and Lee, Eui Chul,,
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  and
        Lee, Eui Chul,, ","href":null},{"type":"text","text":{"content":"“Apparatus
        and method for measuring face symmetry” ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Apparatus
        and method for measuring face symmetry” ","href":null},{"type":"text","text":{"content":"Korean
        Patent Registration No: 10-211515-00000 Date: 2020.05.20","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Korean
        Patent Registration No: 10-211515-00000 Date: 2020.05.20","href":null}],"color":"default"}},{"object":"block","id":"79cb76c5-e64c-4dfb-8f8e-2e7311b44412","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T11:38:00.000Z","last_edited_time":"2024-01-25T04:21:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[R1]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[R1]
        ","href":null},{"type":"text","text":{"content":"Lee, Kunyoung","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Lee,
        Kunyoung","href":null},{"type":"text","text":{"content":"; Lee, E. C.; Kim,
        J. M., Jang, W., Han, J., ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":";
        Lee, E. C.; Kim, J. M., Jang, W., Han, J., ","href":null},{"type":"text","text":{"content":"“Apparatus
        and method for measuring heartbeat using triaxial accelerometer”","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"“Apparatus
        and method for measuring heartbeat using triaxial accelerometer”","href":null},{"type":"text","text":{"content":"
        Korean Patent Registration No: 10-1986213-0000 Date: 2019.05.30","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        Korean Patent Registration No: 10-1986213-0000 Date: 2019.05.30","href":null}],"color":"default"}},{"object":"block","id":"ace6a29c-a063-45c2-aa87-f8238b69c368","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T10:08:00.000Z","last_edited_time":"2024-01-23T11:42:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Patent
        Application","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Patent
        Application","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"3e93bec6-8b1a-45c0-b223-40dea09c9da7","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A7]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A7]
        ","href":null},{"type":"text","text":{"content":"\"원격 심박수 측정을 위한 심박 신호를 선별하는
        방법 및 장치\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"원격
        심박수 측정을 위한 심박 신호를 선별하는 방법 및 장치\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2023-0059266, 출원일: 2023.05.08), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2023-0059266, 출원일: 2023.05.08), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김승현, 박신위, 안병선, 서현수)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김승현, 박신위, 안병선, 서현수)","href":null}],"color":"default"}},{"object":"block","id":"4175c1a1-0f11-4606-ad93-aa0d085ccbb4","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A6]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A6]
        ","href":null},{"type":"text","text":{"content":"\"다중 출력에 대한 표정 인식을 위한 뉴럴
        네트워크 모델의 경량화 장치 및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"다중
        출력에 대한 표정 인식을 위한 뉴럴 네트워크 모델의 경량화 장치 및 방법\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2023-0053584, 출원일: 2023.04.24), 발명자(이의철, 김승현, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2023-0053584, 출원일: 2023.04.24), 발명자(이의철, 김승현, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":")","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":")","href":null}],"color":"default"}},{"object":"block","id":"ef5fbc19-e47c-4887-80c3-19581e066324","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A5]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A5]
        ","href":null},{"type":"text","text":{"content":"\"심박수 산출 장치 및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"심박수
        산출 장치 및 방법\"","href":null},{"type":"text","text":{"content":", 국내특허출원 (출원번호:
        10-2023-0160496, 출원일: 2023.11.20), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2023-0160496, 출원일: 2023.11.20), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김승현, 전용권, 이지은, 이강인)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김승현, 전용권, 이지은, 이강인)","href":null}],"color":"default"}},{"object":"block","id":"95a7a2d2-37f7-48ae-9317-e94ac683ca19","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A4]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A4]
        ","href":null},{"type":"text","text":{"content":"\"원격 광용적맥파신호를 이용한 위조 얼굴 판별
        방법 및 장치\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"원격
        광용적맥파신호를 이용한 위조 얼굴 판별 방법 및 장치\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2022-0109832, 출원일: 2022.08.31), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2022-0109832, 출원일: 2022.08.31), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        유호준, 오재무)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        유호준, 오재무)","href":null}],"color":"default"}},{"object":"block","id":"7639a428-d00c-4d62-8d06-91d53270e7be","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A3]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A3]
        ","href":null},{"type":"text","text":{"content":"\"기계 학습 기반 시선 추적 장치 및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"기계
        학습 기반 시선 추적 장치 및 방법\"","href":null},{"type":"text","text":{"content":", 국내특허출원
        (출원번호: 10-2021-0045737, 출원일: 2021.04.08), 발명자(이의철, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2021-0045737, 출원일: 2021.04.08), 발명자(이의철, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        신유진, 한우정), 출원인(상명대학교산학협력단) (비대면)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        신유진, 한우정), 출원인(상명대학교산학협력단) (비대면)","href":null}],"color":"default"}},{"object":"block","id":"84919c4d-34a5-4b8c-990e-4e5de07d9d75","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:22:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A2]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A2]
        ","href":null},{"type":"text","text":{"content":"\"영상 인식 기반 지폐 일련번호 인식 장치
        및 방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"영상
        인식 기반 지폐 일련번호 인식 장치 및 방법\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2021-0016890, 출원일: 2021.02.05), 발명자(이의철, 장우혁, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2021-0016890, 출원일: 2021.02.05), 발명자(이의철, 장우혁, ","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        전수민, 석채린, 신광용, 이덕형, 김수미, 김상오)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        전수민, 석채린, 신광용, 이덕형, 김수미, 김상오)","href":null}],"color":"default"}},{"object":"block","id":"3802e76e-655e-4ea6-a428-96b15538fc49","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T12:01:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[A1]
        ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[A1]
        ","href":null},{"type":"text","text":{"content":"\"얼굴표정 분석기반 자폐 스펙트럼 장애 평가
        방법\"","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"\"얼굴표정
        분석기반 자폐 스펙트럼 장애 평가 방법\"","href":null},{"type":"text","text":{"content":",
        국내특허출원 (출원번호: 10-2020-0160142, 출원일: 2020.11.25), 발명자(이의철,","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        국내특허출원 (출원번호: 10-2020-0160142, 출원일: 2020.11.25), 발명자(이의철,","href":null},{"type":"text","text":{"content":"이건영","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이건영","href":null},{"type":"text","text":{"content":",
        김영원)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",
        김영원)","href":null}],"color":"default"}},{"object":"block","id":"940de8ef-f24a-47ed-ad6e-1193659c0422","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T06:57:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"90ede0fc-254a-4c9b-9632-ce2b2ac353a1","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-23T12:19:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Research
        Projects","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Research
        Projects","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"ded83e5a-ae10-44f2-90d0-8ef438195780","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T14:00:00.000Z","last_edited_time":"2024-01-25T03:13:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_2","heading_2":{"rich_text":[{"type":"text","text":{"content":"Grant","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Grant","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"b1c5cca3-e194-4338-ba34-dcd1524a190f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T14:47:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국연구재단","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국연구재단","href":null},{"type":"text","text":{"content":"(NRF)]
        비접촉 생체신호 추출 및 생체정보 융합을 통한 이상징후 판별 기술 개발,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(NRF)]
        비접촉 생체신호 추출 및 생체정보 융합을 통한 이상징후 판별 기술 개발,  ","href":null},{"type":"text","text":{"content":"Jul.
        2022 ~ Present\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jul.
        2022 ~ Present\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"과학기술정보통신부","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"과학기술정보통신부","href":null},{"type":"text","text":{"content":"(MSIT)]
        비접촉 생체신호 기반 운동효과 피드백 기능을 갖춘 AI 홈 트레이닝 시스템 제작,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(MSIT)]
        비접촉 생체신호 기반 운동효과 피드백 기능을 갖춘 AI 홈 트레이닝 시스템 제작,  ","href":null},{"type":"text","text":{"content":"Apr.
        2022 ~ Feb. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Apr.
        2022 ~ Feb. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"과학기술일자리진흥원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"과학기술일자리진흥원","href":null},{"type":"text","text":{"content":"(COMPA)]
        머신러닝 화재 판정 모듈 및 AI학습플랫폼 고도화.안정화 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(COMPA)]
        머신러닝 화재 판정 모듈 및 AI학습플랫폼 고도화.안정화 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager,  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager,  ","href":null},{"type":"text","text":{"content":"Oct. ","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Oct.
        ","href":null},{"type":"text","text":{"content":"2021 ~ ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2021
        ~ ","href":null},{"type":"text","text":{"content":"Mar. ","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        ","href":null},{"type":"text","text":{"content":"2023\n[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"2023\n[","href":null},{"type":"text","text":{"content":"산업통상자원부","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"산업통상자원부","href":null},{"type":"text","text":{"content":"(KIAT)]
        안면인식 위변조 보안을 적용한 무인매장 솔루션 연구개발 및 실증,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(KIAT)]
        안면인식 위변조 보안을 적용한 무인매장 솔루션 연구개발 및 실증,  ","href":null},{"type":"text","text":{"content":"Sep.
        2021 ~ Aug. 2022\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Sep.
        2021 ~ Aug. 2022\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국데이터산업진흥원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국데이터산업진흥원","href":null},{"type":"text","text":{"content":"(Kdata)]
        2021 데이터바우처 지원 사업(수요기관:기산전자), ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(Kdata)]
        2021 데이터바우처 지원 사업(수요기관:기산전자), ","href":null},{"type":"text","text":{"content":"
        ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"
        ","href":null},{"type":"text","text":{"content":"Jul. 2021 ~ Nov. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jul.
        2021 ~ Nov. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국전자기술연구원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국전자기술연구원","href":null},{"type":"text","text":{"content":"(KETI)]
        상태데이터 통합 인터페이스 제작,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(KETI)]
        상태데이터 통합 인터페이스 제작,  ","href":null},{"type":"text","text":{"content":"Oct.
        2020 ~ Dec. 2020\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Oct.
        2020 ~ Dec. 2020\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국연구재단","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국연구재단","href":null},{"type":"text","text":{"content":"(NRF)]
        카메라 기반 통합형 자율신경 반응 측정 모델 연구,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(NRF)]
        카메라 기반 통합형 자율신경 반응 측정 모델 연구,  ","href":null},{"type":"text","text":{"content":"Jun.
        2019 ~ Feb. 2022\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jun.
        2019 ~ Feb. 2022\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국연구재단","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국연구재단","href":null},{"type":"text","text":{"content":"(NRF)]
        생체기반 영상정보 정량적 분석 시스템,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(NRF)]
        생체기반 영상정보 정량적 분석 시스템,  ","href":null},{"type":"text","text":{"content":"Mar.
        2017 ~ Feb. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2017 ~ Feb. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"산업통상자원부","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"산업통상자원부","href":null},{"type":"text","text":{"content":"(MOTIE)]
        마음-몸 피드백을 통한 감정 치유를 위한 비접촉식 센싱 기반 인간 내면상태 인식 및 미러링 표출 상호작용 로봇 기술 개발,","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(MOTIE)]
        마음-몸 피드백을 통한 감정 치유를 위한 비접촉식 센싱 기반 인간 내면상태 인식 및 미러링 표출 상호작용 로봇 기술 개발,","href":null},{"type":"text","text":{"content":"  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  ","href":null},{"type":"text","text":{"content":"Mar.
        2017 ~ Aug. 2021","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2017 ~ Aug. 2021","href":null}],"color":"default"}},{"object":"block","id":"b478982e-fc4f-4cca-8e12-753972b3c6aa","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T13:12:00.000Z","last_edited_time":"2024-01-25T03:13:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Contract","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Contract","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"27b78492-10f3-4725-b428-03dd15919b81","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-23T14:14:00.000Z","last_edited_time":"2024-01-25T04:23:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"quote","quote":{"rich_text":[{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"현대엔지비주식회사","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"현대엔지비주식회사","href":null},{"type":"text","text":{"content":"(HYUNDAI
        NGV)] 비전 기반 심박수 측정 시스템 개발 및 고도화, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(HYUNDAI
        NGV)] 비전 기반 심박수 측정 시스템 개발 및 고도화, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",","href":null},{"type":"text","text":{"content":"  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  ","href":null},{"type":"text","text":{"content":"Jul.
        2023 ~ Oct. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jul.
        2023 ~ Oct. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"현대엔지비주식회사","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"현대엔지비주식회사","href":null},{"type":"text","text":{"content":"(HYUNDAI
        NGV)] 운전자 감성인식을 위한 비접촉 생체신호 측정기술 개발 ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(HYUNDAI
        NGV)] 운전자 감성인식을 위한 비접촉 생체신호 측정기술 개발 ","href":null},{"type":"text","text":{"content":"Project
        Manager,  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager,  ","href":null},{"type":"text","text":{"content":"Oct. 2022 ~ Sep.
        2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Oct.
        2022 ~ Sep. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"이후시스","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이후시스","href":null},{"type":"text","text":{"content":"(주)]
        비접촉 생체반응 측정 기술 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(주)]
        비접촉 생체반응 측정 기술 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Aug.
        2022 ~ Jan. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Aug.
        2022 ~ Jan. 2023\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"에스엘주식회사
        진량공장","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"에스엘주식회사
        진량공장","href":null},{"type":"text","text":{"content":"(SL Corporation)] 얼굴
        표정 및 HRV 특징을 이용한 운전자 감정인식 알고리즘 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(SL
        Corporation)] 얼굴 표정 및 HRV 특징을 이용한 운전자 감정인식 알고리즘 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Jun.
        2022 ~ Dec. 2023\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jun.
        2022 ~ Dec. 2023\n","href":null},{"type":"text","text":{"content":"[(주)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[(주)","href":null},{"type":"text","text":{"content":"이모코그","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"이모코그","href":null},{"type":"text","text":{"content":"]
        신경퇴행성 질환자의 생체신호 수집 및 분석 기술 개발,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]
        신경퇴행성 질환자의 생체신호 수집 및 분석 기술 개발,  ","href":null},{"type":"text","text":{"content":"Mar.
        2022 ~ Aug. 2022\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2022 ~ Aug. 2022\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"현대엔지비주식회사","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"현대엔지비주식회사","href":null},{"type":"text","text":{"content":"(HYUNDAI
        NGV)] 비전기반 생체반응 및 행동상태 측정 연구,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(HYUNDAI
        NGV)] 비전기반 생체반응 및 행동상태 측정 연구,  ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",","href":null},{"type":"text","text":{"content":"  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"  ","href":null},{"type":"text","text":{"content":"Dec.
        2021 ~ Dec. 2022\n[주식회사 ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Dec.
        2021 ~ Dec. 2022\n[주식회사 ","href":null},{"type":"text","text":{"content":"애니랙티브","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"애니랙티브","href":null},{"type":"text","text":{"content":"]
        RGB 카메라 기반 생리반응 측정 및 인터렉션 기술개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]
        RGB 카메라 기반 생리반응 측정 및 인터렉션 기술개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Aug.
        2021 ~ Oct. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Aug.
        2021 ~ Oct. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"한국전자기술연구원","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"한국전자기술연구원","href":null},{"type":"text","text":{"content":"(KETI)]
        상태데이터 통합 인터페이스 고도화 용역,  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(KETI)]
        상태데이터 통합 인터페이스 고도화 용역,  ","href":null},{"type":"text","text":{"content":"Jun.
        2021 ~ Nov. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Jun.
        2021 ~ Nov. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"대검찰청","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"대검찰청","href":null},{"type":"text","text":{"content":"(SPO)]
        AI를 이용한 차량번호 인식 기법 연구, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"(SPO)]
        AI를 이용한 차량번호 인식 기법 연구, ","href":null},{"type":"text","text":{"content":"Project
        Manager","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager","href":null},{"type":"text","text":{"content":",  ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":",  ","href":null},{"type":"text","text":{"content":"Mar.
        2021 ~ Dec. 2021\n","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2021 ~ Dec. 2021\n","href":null},{"type":"text","text":{"content":"[","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"[","href":null},{"type":"text","text":{"content":"기산전자","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"기산전자","href":null},{"type":"text","text":{"content":"]
        Deep Learning 기반 PC OCR 엔진 기술 개발, ","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"]
        Deep Learning 기반 PC OCR 엔진 기술 개발, ","href":null},{"type":"text","text":{"content":"Project
        Manager,  ","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Project
        Manager,  ","href":null},{"type":"text","text":{"content":"Mar. 2020 ~ Jun.
        2020","link":null},"annotations":{"bold":false,"italic":true,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Mar.
        2020 ~ Jun. 2020","href":null}],"color":"default"}},{"object":"block","id":"0b21e1e9-777e-4a67-ab43-16a5cf550402","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-22T06:57:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"divider","divider":{}},{"object":"block","id":"5222fc28-9b1d-4283-84cb-f018a9dc81f4","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:46:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_1","heading_1":{"rich_text":[{"type":"text","text":{"content":"Demo(youtube)","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Demo(youtube)","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"c0ee80ca-1517-45f0-962d-b690d44da8c1","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:46:00.000Z","last_edited_time":"2024-01-25T04:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Remote
        Photoplethysmography","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Remote
        Photoplethysmography","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"640641ed-1e3d-4dde-aa36-9dca0f6c7a90","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:47:00.000Z","last_edited_time":"2024-01-25T04:48:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Real-time
        skin segmentation-based remote photoplethysmography","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Real-time
        skin segmentation-based remote photoplethysmography","href":null}],"type":"external","external":{"url":"https://youtu.be/n_agiICg5PQ?si=rWAUoqZ8OjPWojeV"}}},{"object":"block","id":"70395474-0fec-4b17-8e67-b850398c74ca","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:48:00.000Z","last_edited_time":"2024-01-25T04:48:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Application
        of the implemented real-time rPPG signal processing for driver monitoring","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Application
        of the implemented real-time rPPG signal processing for driver monitoring","href":null}],"type":"external","external":{"url":"https://youtu.be/Y4lsUkucfks?si=h9FIschSkHi1ZjEq"}}},{"object":"block","id":"977f9c94-9d4c-4c47-939a-433ab3399f97","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[],"color":"default"}},{"object":"block","id":"c1e0c9eb-40bc-461f-b940-299df7653d9f","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-22T06:57:00.000Z","last_edited_time":"2024-01-25T04:49:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"heading_3","heading_3":{"rich_text":[{"type":"text","text":{"content":"Gaze
        Analysis","link":null},"annotations":{"bold":false,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Gaze
        Analysis","href":null}],"is_toggleable":false,"color":"default"}},{"object":"block","id":"21fa32be-64bc-4614-9e65-ae900e835dbf","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:49:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Infrared
        camera-based gaze tracking with 4-point calibration","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Infrared
        camera-based gaze tracking with 4-point calibration","href":null}],"type":"external","external":{"url":"https://youtu.be/cMd2WTIpTWA?si=EQNGDvuQ-ZAfG45j"}}},{"object":"block","id":"2acb729c-781d-4c2e-8899-8bef00264277","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:50:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"video","video":{"caption":[{"type":"text","text":{"content":"Facial
        behavior analysis based on face and eye landmarks.","link":null},"annotations":{"bold":true,"italic":false,"strikethrough":false,"underline":false,"code":false,"color":"default"},"plain_text":"Facial
        behavior analysis based on face and eye landmarks.","href":null}],"type":"external","external":{"url":"https://youtu.be/1uOyHijAFpQ?si=uT9DITi--88CRc9J"}}},{"object":"block","id":"918d086e-86e3-4c36-972b-55128985bd6d","parent":{"type":"page_id","page_id":"83817704-3c47-4405-bcbc-09826a13153b"},"created_time":"2024-01-25T04:50:00.000Z","last_edited_time":"2024-01-25T04:50:00.000Z","created_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"last_edited_by":{"object":"user","id":"cc53e593-2403-4348-9785-9686456ff120"},"has_children":false,"archived":false,"type":"paragraph","paragraph":{"rich_text":[],"color":"default"}}],"next_cursor":null,"has_more":false,"type":"block","block":{},"request_id":"50b93ea1-fe77-4c1a-8d37-0e83def88744"}'
  recorded_at: Thu, 25 Jan 2024 05:16:51 GMT
recorded_with: VCR 6.2.0
